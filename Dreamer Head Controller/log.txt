Dreamer Head Redesign v57.0

2016.10.12
   Finally got lights.s working completely as desired, meaning that we can send arbitrary color values at any time. One eventual modification might be to make two update functions, one that takes 1xuint32_t for all lights, and a second that takes 2x40xuint32_t that can update all lights individually. That's a luxury goal for the future.

2016.09.28
   Working on lights.s, changing lightsUpdate() to take input of arbitrary new
color. This requires rewriting of most existing file. Also, moving lightsInit()
to assembly, since it's the only thing left in lights.c. Will test and debug tomorrow.

2016.09.27
   Modified v0.9 to enable interpreter control. Interpreter works just fine, 
receives and processes with no problems observed. Remote control was implemented
by receiving gaze parameters from remote, then inserting those into random gaze 
parameter generation function in motion planner. Motion planner look counter is 
also modifed so that it does not decrement naturally. Instead, it is set to zero
when new gaze commands are received. Head then holds ordered position until new 
commands are received. This change can be implemented with only a few changed 
lines of code.
   For future use, remote control should be a standard feature available at any 
time without reprogramming of the Tiva MCU. We should program the interpreter to
take input of program start/stop commands. The random gaze planner would then 
run automatically at startup, but could be stopped and replaced by remote 
control or anything else at any future point via a serial command. The most 
sophisticated way to do this would be to essentially replace the existing 
program with an OS, and the various motion controllers as threads running on 
that OS, but since the only two programs we currently have planned are the 
default random motion and occassional remote control, we'll just use that for 
now. We can put the few lines of modified code inside conditional statements and
control the switch that way.

2016.09.24
   Posted release build v0.9. This version is very stable and includes all
essential control features plus random movement demo. Does not include a
generic motion controller or interpreter allowing for remote control. That will
be the next thing to develop. In order to do anything involving vision, we'll
need to cede motion control to an external computer, which will require a
completed interpreter.

2016.09.19
   Several updates, mostly fixes of bugs previously mentioned. Rewrote ear light
code in ASM, runs exactly at timing recommendations and within requirements. 
Need to improve code so we can pass arbitrary color value, instead of current
system that writes predefined values.
   Changed build naming system. "Version x.x" will only be used for polished
releases. "TestBuildxxxx" will be used for rough test builds, with 'a' of
"TestBuildaxxx" being most recent polished release number.This makes keeping
track of version number much easier.

2016.09.16
   Wow, haven't updated this in a long time. We finished the PCB design (good
enough), manufactured, assembled, and installed them, and now we're removing
final bugs. We have a problem with the ear lights in that the bit banging code
isn't running fast enough and the end of the signal is getting cut off. We will
attempt to fix that by rewriting the signal generation code in assembly. We are
also in the middle of repainting the head. We have mounted the head back on top
of the torso, routed all cables through the neck/torso/base, and almost finished
physically integrating the two systems. The head/torso are still completely
separate robots as far as software and controls are concerned.
   For the past few days we've been working on the eyes. The cameras are up and
running, but we do not yet know how to interface them with other software. They
appear as a different type of hardware than most other webcams and we will have
to figure out how to read them with OpenCV and ROS. The immediate goal is to
have Dreamer doing face tracking within the next week. That's essentially the
baseline demo we've wanted for the past several years. It's very close.

2016.09.09
   Dreamer head operational, debugging last few problems and upgrading motion
planner
   As of a few days ago, Dreamer's head is ~99% operational. All twelve DOFs are
running smoothly and the ear lights mostly work. We still have a problem with
the bitbanging timing in the light control signals.
   The next thing we're going to do is add to the motion planner, making it sort
of a "fuzzy" motion planner. In other words, we send a command to the motors,
but an intermediate task adds a random deviation to that order. This deviation
is a vector that changes smoothly and continuously, causing the head to do a
small, slow random walk around its desired gaze. Since this is a purely
heuristic feature, it will require a lot of tuning. We'll work on creating a
kinematically correct gaze motion planner (a motion planner that produces head
motions based on the actual dimensions of the head, so that the eyes actually
focus on the correct point, instead of looking forward roughly parallel, as they
currently do; technically, they're not actually parallel, they're just close to
parallel, we haven't measured their angles directly, just their joint ranges) in
the near future. That will probably run on an external PC, not on the embedded
MCU, at least at first. If we produce a kinematically correct planner with low
computational requirements, we can put that on the head as the default demo.
   Of course, the ultimate goal will be to have the head react to visual data,
so motion planning and high level control will be performed completely by an
external PC, since we currently have no way of connecting the cameras to an
embedded PC.

2016.07.24 Dreamer Head Motion Planner
Blinking is random, independent from other actions
All other actions are built around gaze
Gaze utilizes three variable: pitch, yaw, and focal length
J00 (neck pitch)
    Neck pitch is function of focal length only. Neck leans forward as focal 
    length increases.
J01 (head yaw)
    Head yaw = 2/3 of gaze yaw.
J02 (head roll)
    Head rolls ~= 1/3 gaze yaw. Head rolls left as head yaws right, and vice 
    versa.
J03 (head pitch)
    Head pitch = 2/3 gaze pitch
J04 (eye pitch)
    Eye pitch = 1/3 gaze pitch
J05 (right eye yaw)
    Right eye yaw = 1/3 of gaze yaw.
J06 (left eye yaw)
    Left eye yaw = 1/3 of gaze yaw.
J07 (eyelid position)
    Eyelid position is function of focal length only. Eyelids close as focal 
    length increases.
J0pos = atan((max_focus - min_focus)*random + min_focus);
J1pos = 2*gaze_yaw/3;
J2pos = -gaze_yaw/3;
J3pos = 2*gaze_pitch/3;
J4pos = gaze_pitch/3;
J5pos = gaze_yaw/3;
J6pos = gaze_yaw/3;
J7pos = atan()
focal length transformation: atan(pi*x/3 - 3)/pi + 0.4

2016.07.10
   Did a lot more testing, debugging, redesigning, etc. At this point, 
everything works. We have twelve DOFs running at a determininstic 550Hz. We're 
reading all the encoders with no problems. We're writing all the PWM control 
signals. We're reading the e-stop position and controlling the ear lights. We've
3d printed replacement parts for the eyes and ears. We've installed the new eye 
encoders. We've tested everything on breadboards. All that's left to do is check
the PCB designs for the tenth time and order them. When those arrive, we should 
have Dreamer's head up and running at 100% capacity for the first time ever. 
Should be cool.
   Changes: For a while we were planning to use two TM4C boards inside the head.
One would read encoders and write PWMs. The other would handle motion planning, 
e-stop, and lights. We decided not to do that. It's unnecessarily complicated. 
We also tried some interesting memoryless motion planning equations that would 
ensure that we always have smooth, speed- and acceleration-limited movement. But
no matter how that's implemented, it would always restrict our abilities. It 
makes more sense to have the simplest possible controls built in and sealed off 
at the MCU level. Currently we're back to the original idea of using GPIO pins 
to bitbang signals to the ear lights. There's nothing wrong with that, but it 
uses up more than half of our CPU time. We'll try to offload the light signals 
to I2C or SPI in the future. That will require new PCBs, so it will be low 
priority.

2016.06.27
   Updated ear lights bit timing code. Works, but isn't perfect. Individual bits
are too slow. Instead of running at 800KHz as intended, runs at ~600KHz. Timer 
Handler function is already pretty well optimized for speed. Can't do much more 
there. Lights work fine now, showing single colors at 10-20Hz update rate. If we
want multiple colors or more precise signal timing, we'll need to offload LED 
signals to SPI or I2C instead of bit banging via GPIO. We'll worry about that if
it becomes a problem.
   Fixed typos and truncation errors in a few places. Spent some time trying to 
diagnose problems associated with PA6 and PE0. Realized these pins were damaged,
worked fine on different boards.
   Have now tested PID control on all twelve channels. EStop works, encoders 
work, PID works, PWM works, controller is complete and ready to be installed.
Have to 3d print some parts for ears and assemble optocoupler/level shifter PCB 
to interface TM4C with Maxon drivers. After that's done, will install in 
Dreamer's head.

2016.06.23
   Finished testing current v0.5. lights and e-stop work well. Will assemble
single dof testbed, fix any bugs, then assemble entire head.

2016.06.22
   Added code to update lights every cycle. Currently only accept one color for 
all lights, both ears. Might add option to write individual colors to individual
LEDs later on, but that takes up a lot of bandwidth and the ears intentionally
diffuse the LED light, so not sure how useful that would be. Making ears
different solid colors might also be useless, because you can't see both of them
at the same time. Have not yet tested signal output because don't have a scope
with me, but it doesn't make anything crash.
   Added code to read hardware e-stop and write software e-stop. Will place
software controlled relay in series with hardware button. Works perfectly.
   Last feature to add is interpreter. Will accept all commands as uint32 
values. This is big enough to contain any single command we want to send. Each 
joint position is <= 14 bits, so we can include two joints per command. Ear 
colors are 24 bits. Software EStop commands are one bit. We'll put a 4-bit 
identifier at the beginning of each command.
   Archiving v0.4 even though lights are untested, moving to v0.5.

2016.06.21
   Did a lot of work on v0.3. Encoder reading and PWM writing is complete. Can 
do 12-dof P control at 2200Hz with no problems. Have a bit of code left to 
write.
   Need to create:
-I and D error functions so we have proper PID control
-interpreter to accept commands from external controller
-ear lights control
-read e-stop position
   Considering different options for D error calculation. Want it to be as fast
as possible, under 5-10 cycles delay. Will try calculating and storing multiple
point-to-point derivatives and running them through median filter.
Interpreter needs to take position commands from controller and give status
feedback to controller. Want to run TM4C at 2.2KHz in final form if possible, so
will probably not do motion planning on board there. Will merely take position
commands from master. Will provide feedback of joint positions, velocities, and
head e-stop status.
   v0.3 is stable and complete in current form. Archiving, moving to v0.4.

2016.06.19
   Started redesigning Dreamer's Head Control Systems a few days ago using TI 
TM4C chips instead of Arduinos. They're vastly more powerful, have many times 
more features, and are cheaper. Most importantly, it occurred to me on Friday 
that we don't need one MCU per one or two joints, as Meka used them. A single 
TM4C has enough features and speed to control all twelve joints for position 
control at several hundred hertz. It's nowhere near as fast as the Ethercat 
system Meka set up, but it doesn't need to be and it should work many, many 
times more reliably.
   v0.1 code was designed to prove all needed features. We have twelve PWM 
outputs for motor control of twelve joints and we use GPIO pins to read twelve 
encoders in parallel. We could add on MOSFETS, as Contelec recommends, or 
tristate buffers, as we did in past redesigns, but the TM4C is fast enough to 
just switch between output and input as needed, so we're planning on doing that 
and not requiring and additional hardware. All encoder signals are produced by 
bit banging, a thousand lines of timing control spins per message.
   v0.2 code is designed to use timer interrupts instead of spinning between 
signal changes. The only actual advantage to this is that the code is more 
attractive. There's nothing wrong with ugly bit banging.
   v0.3 code is a continuation of v0.1. After testing v0.2, it was found that 
nice, clean, well abstracted code was far too slow, and completely procedural
bit banging was necessary. We'll be using this ugly but fast technique from now 
on.
